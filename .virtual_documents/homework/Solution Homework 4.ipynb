





import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


# Function that returns the time-series model's parameters and annualized statistics for multiple assets and factors
def LFPM_TS(assets, factors, annualize = 12, name = 'asset', treynor = False, mkt_name = 'MKT'):
    
    if isinstance(assets,pd.Series):
        assets = pd.DataFrame(assets,columns=name)
    
    model_output = pd.DataFrame()
    stats_output = pd.DataFrame()
    
    x = sm.add_constant(factors)
    
    for asset in assets.columns:
        
        y = assets[asset]
        model = sm.OLS(y,x).fit()
        
        model_output[asset] = model.params
        
        mu = y.mean() * annualize
        alpha = model.params[0] * annualize
        sig_ep = model.resid.std() * np.sqrt(annualize)
        IR = alpha / sig_ep
        
        stats_output[asset] = pd.Series(data = [alpha,IR],index = ['Alpha','IR'])
        
        if treynor:
            mkt = model.params[mkt_name]
            TR = mu / mkt
            
            stats_output.loc['Treynor',asset] = TR
        
    return model_output, stats_output


# Function that returns the cross-sectional model: we regress the means on the betas, with each asset as a data point
def LFPM_CS(assets, factors, intercept = True, annualize = 12):
    
    coef = LFPM_TS(assets,factors,annualize)[0]
    
    y = assets.mean() * annualize
    x = coef.drop('const').transpose()
    
    if intercept:
        x = sm.add_constant(x)

    model = sm.OLS(y,x).fit()
    
    return model


























factors = pd.read_excel('dfa_analysis_data.xlsx',sheet_name='factors',index_col='Date')
data = factors.drop('RF',axis = 1)





# Create function to retrieve common statistics
def stats_mean_vol_sharpe(data,portfolio = None,portfolio_name = 'Portfolio',annualize = 12):
    
    if portfolio is None:
        returns = data
    else:
        returns = data @ portfolio
    
    output = returns.agg(['mean','std'])
    output.loc['sharpe'] = output.loc['mean'] / output.loc['std']
    
    output.loc['mean'] *= annualize
    output.loc['std'] *= np.sqrt(annualize)
    output.loc['sharpe'] *= np.sqrt(annualize)
    
    if portfolio is None:
        pass
    else:
        output.columns = [portfolio_name]
    
    return output


# Set VaR quantile
pi = 0.05





# Historic VaR or normally distributed VaR?


data_beg_to_1980 = data.loc[:'1980']
_ = data_beg_to_1980.quantile(pi).rename('VaR')

stats_beg_to_1980 = stats_mean_vol_sharpe(data_beg_to_1980)
stats_beg_to_1980.loc['VaR'] = _
stats_beg_to_1980





data_1981_to_2001 = data.loc['1981':'2001']
_ = data_1981_to_2001.quantile(pi).rename('VaR')

stats_1981_to_2001 = stats_mean_vol_sharpe(data_1981_to_2001)
stats_1981_to_2001.loc['VaR'] = _
stats_1981_to_2001





data_2002_to_end = data.loc['2002':]
_ = data_2002_to_end.quantile(pi).rename('VaR')

stats_2002_to_end = stats_mean_vol_sharpe(data_2002_to_end)
stats_2002_to_end.loc['VaR'] = _
stats_2002_to_end











corr = data.corr()
corr.round(2)





# First subsample
data_beg_to_1980.corr().round(2)


# Second subsample
data_1981_to_2001.corr().round(2)


# Third subsample
data_2002_to_end.corr().round(2)








(data_1981_to_2001 + 1).cumprod().plot(figsize = (15, 7))
plt.title('1981 to 2001')
plt.ylabel('Cumulative Return')
plt.show()





(data_2002_to_end + 1).cumprod().plot(figsize = (15, 7))
plt.title('2002 to End')
plt.ylabel('Cumulative Return')
plt.show()











portfolios = pd.read_excel('dfa_analysis_data.xlsx',sheet_name='portfolios (total returns)',index_col='Date')
rfr = pd.read_excel('dfa_analysis_data.xlsx',sheet_name='factors',index_col='Date')[['RF']]

portfolios = portfolios.subtract(rfr['RF'],axis=0)
portfolios = portfolios.loc['1981':]





_ = portfolios.quantile(pi).rename('VaR')

stats_portfolios = stats_mean_vol_sharpe(portfolios)
stats_portfolios.loc['VaR'] = _
stats_portfolios.transpose()


stats_portfolios.loc[['mean','std']].transpose().plot(kind = 'scatter',x='std',y='mean',figsize = (10, 6))
plt.show()


stats_portfolios.loc[['mean','VaR']].transpose().plot(kind = 'scatter',x='VaR',y='mean',figsize = (10, 6))
plt.show()








import statsmodels.api as sm


# Create a function to display regression statistics
# Pass series into y, dataframe or series into x
def statsmodel_statistics(model, y, x, intercept=True, annualize=12):
    
    if intercept:
        alpha = model.params.iloc[0] * annualize
        betas = model.params.iloc[1:]
    else:
        betas = model.params.iloc[0:]
    
    
    mu_y = y.mean() * annualize
    resid_std = model.resid.std() * np.sqrt(annualize)
    
    treynor_ratio = mu_y / betas
    information_ratio = alpha / resid_std
    
    output = model.params.to_frame(name='Coef')
    output['Treynor'] = treynor_ratio
    
    return alpha, information_ratio, output





def LFPM_TS(assets, factors, annualize = 12, name = 'asset', treynor = False, mkt_name = 'Mkt-RF'):
    
    if isinstance(assets,pd.Series):
        assets = pd.DataFrame(assets,columns=name)
    
    model_output = pd.DataFrame()
    stats_output = pd.DataFrame()
    
    x = sm.add_constant(factors)
    
    for asset in assets.columns:
        
        y = assets[asset]
        model = sm.OLS(y,x).fit()
        
        model_output[asset] = model.params
        
        mu = y.mean() * annualize
        alpha = model.params.iloc[0] * annualize
        sig_ep = model.resid.std() * np.sqrt(annualize)
        IR = alpha / sig_ep
        
        stats_output[asset] = pd.Series(data = [alpha,IR],index = ['Alpha','IR'])
        
        if treynor:
            mkt = model.params[mkt_name]
            TR = mu / mkt
            
            stats_output.loc['Treynor',asset] = TR
        
    return model_output, stats_output


capm_ts_reg_stats = pd.concat(LFPM_TS(portfolios,data['Mkt-RF'].loc['1981':], treynor=True)).T
print(f"MAE: {capm_ts_reg_stats['const'].abs().mean():.4f}")
print(f"MAE (Annualized): {capm_ts_reg_stats['Alpha'].abs().mean():.4f}")
capm_ts_reg_stats








mu_tilde_portfolios = portfolios.mean()
mkt_betas_portfolios = capm_ts_reg_stats['Mkt-RF']

y = mu_tilde_portfolios
x = sm.add_constant(mkt_betas_portfolios)

model_cross_sectional = sm.OLS(y,x).fit()


print(model_cross_sectional.summary())





plt.scatter(x=mkt_betas_portfolios, y=mu_tilde_portfolios); plt.xlabel('Mkt Beta'); plt.ylabel('Mean Excess Return'); plt.show()














# Create function to calculate sigma, sigma_inv, n, and mu_tilde
def get_symbols(data, diagonalize = False):
    
    sigma = data.cov()
    
    if diagonalize == True:
        sigma = np.diag(np.diag(sigma))
    
    sigma_inv = np.linalg.inv(sigma)
    n = sigma.shape[0]
    mu = data.mean().to_numpy().reshape((n,1))
    
    return sigma, sigma_inv, n, mu

# Create function to compute and return the tangency portfolio weights
def compute_tangency(data, diagonalize = False):
    
    sigma, sigma_inv, n, mu = get_symbols(data,diagonalize)
    
    ones = np.ones((n,1))
    
    portfolio = (sigma_inv @ mu) / (ones.transpose() @ sigma_inv @ mu)
    
    return portfolio


in_sample_tangency = (portfolios @ compute_tangency(portfolios)).iloc[:, 0].rename('tangency')


tangency_reg_stats = pd.concat(LFPM_TS(portfolios, in_sample_tangency, treynor=True, mkt_name='tangency')).T
print(f"MAE: {tangency_reg_stats['const'].abs().mean():.4f}")
print(f"MAE (Annualized): {tangency_reg_stats['Alpha'].abs().mean():.4f}")
tangency_reg_stats





tangency_betas_portfolios = tangency_reg_stats['tangency']

y = mu_tilde_portfolios
x = sm.add_constant(tangency_betas_portfolios)

model_cross_sectional_tangency = sm.OLS(y, x).fit()


print(model_cross_sectional_tangency.summary())


plt.scatter(x=tangency_betas_portfolios, y=mu_tilde_portfolios); plt.xlabel('Tangency Beta'); plt.ylabel('Mean Excess Return'); plt.show()








ff3_reg_stats = pd.concat(LFPM_TS(portfolios, factors[['Mkt-RF', 'SMB', 'HML']].loc['1981':], treynor=True, mkt_name='Mkt-RF')).T
print(f"MAE: {ff3_reg_stats['const'].abs().mean():.4f}")
print(f"MAE (Annualized): {ff3_reg_stats['Alpha'].abs().mean():.4f}")
ff3_reg_stats





ff3_betas_portfolios = ff3_reg_stats[['Mkt-RF', 'SMB', 'HML']]

y = mu_tilde_portfolios
x = sm.add_constant(ff3_betas_portfolios)

model_cross_sectional_ff3 = sm.OLS(y, x).fit()


print(model_cross_sectional_ff3.summary())


plt.scatter(x=ff3_betas_portfolios['Mkt-RF'], y=mu_tilde_portfolios); plt.xlabel('Market Beta'); plt.ylabel('Mean Excess Return'); plt.show()


plt.scatter(x=ff3_betas_portfolios['SMB'], y=mu_tilde_portfolios); plt.xlabel('SMB Beta'); plt.ylabel('Mean Excess Return'); plt.show()


plt.scatter(x=ff3_betas_portfolios['HML'], y=mu_tilde_portfolios); plt.xlabel('HML Beta'); plt.ylabel('Mean Excess Return'); plt.show()








from scipy import stats


alpha_vec = pd.Series()
epsilon_mtx = pd.DataFrame()

x = sm.add_constant(factors['Mkt-RF']).loc['1981':]

for port in portfolios.columns:
    
    y = portfolios[port]
    
    model = sm.OLS(y, x).fit()
    alpha = model.params.iloc[0]
    epsilon = model.resid
    
    alpha_vec[port] = alpha
    epsilon_mtx[port] = epsilon
    
market_sharpe = factors['Mkt-RF'].mean() / factors['Mkt-RF'].std()

T = y.shape[0]
sigma = epsilon_mtx.cov()

H = T * (1 + market_sharpe ** 2) ** (-1) * (alpha_vec.T @ np.linalg.inv(sigma) @ alpha_vec)
pvalue = 1 - stats.chi2.cdf(H, df=25)

print(f'{H = :.4f}')
print(f'{pvalue = :.4f}')



