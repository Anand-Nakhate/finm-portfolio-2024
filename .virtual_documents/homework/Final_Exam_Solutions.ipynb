
















































































import pandas as pd
import numpy as np
import statsmodels.api as sm

import os
if not os.getcwd().endswith("data"):
    os.chdir("../data")


portfolio = pd.read_excel('final_exam_data.xlsx', sheet_name = 'portfolio') ##weekly
forecasting = pd.read_excel('final_exam_data.xlsx', sheet_name = 'forecasting').set_index('date') ##monthly
fx_data = pd.read_excel('final_exam_data.xlsx', sheet_name = 'fx_carry', index_col=0) ## daily





def performance_summary(return_data, annualization = 12):
    """ 
        Returns the Performance Stats for given set of returns
        Inputs: 
            return_data - DataFrame with Date index and Monthly Returns for different assets/strategies.
        Output:
            summary_stats - DataFrame with annualized mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and
                            CVaR (0.5) and drawdown based on monthly returns. 
    """
    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*annualization)
    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(annualization))
    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']
    
    summary_stats['Skewness'] = return_data.skew()
    summary_stats['Excess Kurtosis'] = return_data.kurtosis()
    summary_stats['VaR (0.05)'] = return_data.quantile(.05, axis = 0)
    summary_stats['CVaR (0.05)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()
    summary_stats['Min'] = return_data.min()
    summary_stats['Max'] = return_data.max()
    
    wealth_index = 1000*(1+return_data).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/previous_peaks

    summary_stats['Max Drawdown'] = drawdowns.min()
    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]
    summary_stats['Bottom'] = drawdowns.idxmin()
    
    recovery_date = []
    for col in wealth_index.columns:
        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()
        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T
        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())
    summary_stats['Recovery'] = recovery_date
    
    return summary_stats





def time_series_regression(portfolio, factors, multiple_factors = False, resid = False, annualization = 1):
    
    ff_report = pd.DataFrame(index=portfolio.columns)
    bm_residuals = pd.DataFrame(columns=portfolio.columns)

    rhs = sm.add_constant(factors)

    for portf in portfolio.columns:
        lhs = portfolio[portf]
        res = sm.OLS(lhs, rhs, missing='drop').fit()
        ff_report.loc[portf, 'alpha_hat'] = res.params['const']*annualization
        if multiple_factors:
            ff_report.loc[portf, factors.columns[0] + ' beta'] = res.params[1]
            ff_report.loc[portf, factors.columns[1]+ ' beta'] = res.params[2] 
        else:
            ff_report.loc[portf, factors.name + ' beta'] = res.params[1]

            
        ff_report.loc[portf, 'info_ratio'] = np.sqrt(12) * res.params['const'] / res.resid.std()
        ff_report.loc[portf, 'treynor_ratio'] =  annualization* portfolio[portf].mean() / res.params[1]
        ff_report.loc[portf, 'R-squared'] = res.rsquared
        ff_report.loc[portf, 'Tracking Error'] = (res.resid.std()*np.sqrt(12))

        if resid:
            bm_residuals[portf] = res.resid
            
            
        
    if resid:
        return bm_residuals
        
    return ff_report





def tangency_weights(returns, cov_mat = 1):
    
    if cov_mat ==1:
        cov_inv = np.linalg.inv((returns.cov()*12))
    else:
        cov = returns.cov()
        covmat_diag = np.diag(np.diag((cov)))
        covmat = cov_mat * cov + (1-cov_mat) * covmat_diag
        cov_inv = np.linalg.inv((covmat*12))  
        
    ones = np.ones(returns.columns[1:].shape) 
    mu = returns.mean()*12
    scaling = 1/(np.transpose(ones) @ cov_inv @ mu)
    tangent_return = scaling*(cov_inv @ mu) 
    tangency_wts = pd.DataFrame(index = returns.columns[1:], data = tangent_return, columns = ['Tangent Weights'] )
        
    return tangency_wts





def gmv_weights(tot_returns):
    
    ones = np.ones(tot_returns.columns[1:].shape)
    cov = tot_returns.cov()*12
    cov_inv = np.linalg.inv(cov)
    scaling = 1/(np.transpose(ones) @ cov_inv @ ones)
    gmv_tot = scaling * cov_inv @ ones
    gmv_wts = pd.DataFrame(index = tot_returns.columns[1:], data = gmv_tot, columns = ['GMV Weights'] )

    
    return gmv_wts






def mv_portfolio_excess_returns(target_ret, ex_ret):
    
    mu_tilde = ex_ret.copy().set_index('date').mean()
    
    Sigma_adj = ex_ret.copy().set_index('date').cov()
    
    Sigma_inv = np.linalg.inv(Sigma_adj)
    
    N = Sigma_adj.shape[0]
    
    delta_tilde = ((np.ones(N) @ Sigma_inv @ mu_tilde)/(mu_tilde @ Sigma_inv @ mu_tilde)) * target_ret
    
    omega_star = delta_tilde * tan_wts
    
    return omega_star
    


def mv_portfolio(target_ret, tot_returns):
    
    mu_tan = tot_returns.mean() @ tangency_weights(tot_returns, cov_mat = 1)
    mu_gmv = tot_returns.mean() @ gmv_weights(tot_returns)
    
    delta = (target_ret - mu_gmv[0])/(mu_tan[0] - mu_gmv[0])
    mv_weights = (delta * tangency_weights(tot_returns, cov_mat = 1)).values + ((1-delta)*gmv_weights(tot_returns)).values
    
    MV = pd.DataFrame(index = tot_returns.columns[1:], data = mv_weights, columns = ['MV Weights'] )
    MV['tangency weights'] =  tangency_weights(tot_returns, cov_mat = 1).values
    MV['GMV weights'] =   gmv_weights(tot_returns).values


    return MV






def OOS_strat(df, factors, start):
    y = df
    X = sm.add_constant(factors)

    forecast_err, null_err,oos_predictions,null_predictions = [], [],[],[]

    for i,j in enumerate(df.index):
        if i >= start:
            currX = X.iloc[:i]
            currY = y.iloc[:i]
            reg = sm.OLS(currY, currX, missing = 'drop').fit()
            null_forecast = currY.mean()
            reg_predict = reg.predict(X.iloc[[i]])
            actual = y.iloc[[i]]
            oos_predictions.append(reg_predict.T)
            null_predictions.append(pd.DataFrame([[reg_predict.index[0]]], columns = ['date'], index = [null_forecast]))
            forecast_err.append(reg_predict.values - actual)
            null_err.append(null_forecast.values - actual)
            
    RSS = (np.array(forecast_err)**2).sum()
    TSS = (np.array(null_err)**2).sum()
    predictions_df = pd.concat(oos_predictions).T.drop_duplicates()
    null_predictions_df = pd.concat(null_predictions).T
    
    return ((1 - RSS/TSS),reg,predictions_df,null_predictions_df)





def OOS_r2(df, factors, start):
    y = df['SPY']
    X = sm.add_constant(factors)

    forecast_err, null_err = [], []

    for i,j in enumerate(df.index):
        if i >= start:
            currX = X.iloc[:i]
            currY = y.iloc[:i]
            reg = sm.OLS(currY, currX, missing = 'drop').fit()
            null_forecast = currY.mean()
            reg_predict = reg.predict(X.iloc[[i]])
            actual = y.iloc[[i]]
            forecast_err.append(reg_predict - actual)
            null_err.append(null_forecast - actual)
            
    RSS = (np.array(forecast_err)**2).sum()
    TSS = (np.array(null_err)**2).sum()
    
    return ((1 - RSS/TSS),reg)








tan_wts = tangency_weights(portfolio, cov_mat = 1)
tan_wts


mv_er = mv_portfolio_excess_returns(0.0025, portfolio)
mv_er





gmv_wts = gmv_weights(portfolio)
gmv_wts


mv_wts = mv_portfolio(0.0025, portfolio)
mv_wts











excess_ret_wo_BTC = portfolio.drop(columns = {'BTC'})
excess_ret_wo_BTC_IS = excess_ret_wo_BTC.set_index('date').loc[:'2021']
excess_ret_wo_BTC_OOS = excess_ret_wo_BTC.set_index('date').loc['2022':'2023']
target_ret = 0.0025


wts = pd.DataFrame(index = excess_ret_wo_BTC_IS.columns, columns = ['tangency','equal weights'])
wts.loc[:,'tangency'] = tangency_weights(excess_ret_wo_BTC_IS.reset_index(), cov_mat = 1)
wts.loc[:,'equal weights'] = 1/len(excess_ret_wo_BTC_IS.columns)
wts *= target_ret / (excess_ret_wo_BTC_IS.mean()@wts)
wts


a = performance_summary(excess_ret_wo_BTC_OOS @ wts[['tangency']], 52)
b = performance_summary(excess_ret_wo_BTC_OOS @ wts[['equal weights']], 52)
a.append(b)














USO = forecasting.loc[:,['USO']]
signal = ['Tnote rate','Tnote rate change']
factors = forecasting.loc[:,['Tnote rate','Tnote rate change']].shift(1)
signal_reg = time_series_regression(USO, factors, multiple_factors=True, resid=False)
signal_reg






forecasted_rets = (np.array(forecasting.shift(1).loc[:,['Tnote rate','Tnote rate change']]) 
                   @ np.array(signal_reg.loc[:,['Tnote rate beta','Tnote rate change beta']].T))

forecast_ret = (pd.DataFrame(forecasted_rets,columns = ['Forecasted Return'],index= forecasting.index)) 

forecast_ret['Forecasted Return'] = (forecast_ret['Forecasted Return'] + 
                                     float(signal_reg['alpha_hat']))*50 + 0.5

strat = pd.DataFrame(forecast_ret['Forecasted Return'] * forecasting.loc[:,['USO']]['USO'], 
                     columns=forecast_ret.columns, 
                     index=forecast_ret.index).dropna()

display(strat.head())

display(strat.tail())





strat = strat.merge(forecasting[['USO']], left_index = True, right_index = True)
forecast_summary = performance_summary(strat, annualization=12)
forecast_summary.loc[:,['Mean','Volatility','Sharpe Ratio','Max Drawdown']]








time_series_regression(strat[['Forecasted Return']], strat['USO'].squeeze(), multiple_factors=False, resid=False, annualization = 12)





time_series_regression(strat[['Forecasted Return']], strat['USO'].squeeze(), multiple_factors=False, resid=False)








factor = forecasting.loc[:,['Tnote rate','Tnote rate change']].shift(1)
fund_ret = USO.loc[factor.index[0]:,['USO']]
OOS_r2, OOS_reg_params, OOS_forecasts, null_predictions_df = OOS_strat(fund_ret,factor, forecasting.loc[:'2017'].shape[0])
OOS_pred = OOS_forecasts.to_frame('OOS Forecast')
baseline_pred = null_predictions_df.T.reset_index().set_index('date').rename(columns = {'level_0':'Baseline Forecasts'})


display(OOS_pred.head())
display(OOS_pred.tail())





pd.DataFrame([[OOS_r2]], columns = ['R-Squared'], index = ['OOS Forecast'])








merged_OOS_df = OOS_pred.merge(USO.loc[OOS_pred.index], left_index = True, right_index = True)
merged_OOS_df.corr()


plt.figure(figsize=(16, 6))
heatmap = sns.heatmap(merged_OOS_df.corr(), vmin=-0.5, vmax=1, annot=True)
heatmap.set_title('Asset Correlation Heatmap', fontdict={'fontsize':12}, pad=12);








allocation = merged_OOS_df[['USO']]
allocation['allocation for OOS forecast'] = merged_OOS_df['OOS Forecast']*50 + 0.5
allocation['returns OOS with allocation'] = allocation['allocation for OOS forecastb'] * merged_OOS_df['USO']
allocation[['USO','returns OOS with allocation']]
performance_summary(allocation[['USO','returns OOS with allocation']])

















log_fx_data = np.log(1 + fx_data)
log_fx_data['MXN'] = np.log(fx_data['MXN']).fillna(method='ffill')
log_fx_data.mean().to_frame("Mean").T





fx_ret = log_fx_data["MXSTR"].shift(1) - log_fx_data["SOFR"].shift(1) + log_fx_data["MXN"].diff()


excess_log_ret.mean() * 252


log_fx_data['MXN_diff'] = log_fx_data['MXN'].diff().shift(-1)
excess_log_ret = log_fx_data['MXN_diff'] - (log_fx_data['SOFR'] - log_fx_data['MXSTR'])
res = [excess_log_ret.mean() * 252, excess_log_ret.std() * np.sqrt(252), excess_log_ret.mean() / excess_log_ret.std() * np.sqrt(252)]
res = pd.DataFrame(res, index=['Mean', 'Std', 'Sharpe'], columns=['Excess log return'])
res





res = [excess_log_ret.mean()*252, log_fx_data['MXN_diff'].mean()*252, -(log_fx_data['SOFR'] - log_fx_data['MXSTR']).mean() * 252]
res = pd.DataFrame(res, index=['Excess log return', 'Spot Change', 'Interest Spread'], columns=['Annualized'])
res








model = sm.OLS(log_fx_data['MXN_diff'], sm.add_constant(log_fx_data['SOFR'] - log_fx_data['MXSTR']), missing = 'drop').fit()
res = [model.params['const'], model.params[0], model.rsquared]
res = pd.DataFrame(res, index = ['alpha', 'Beta', 'R-squared'], columns = ['OLS stats']).T
res























res = []
spread = (log_fx_data['SOFR'] - log_fx_data['MXSTR'])
res.append(spread.autocorr())
res.append(spread.diff().autocorr())
res = pd.DataFrame(res, index = ['Spread', 'Spread Diff'], columns = ['Autocorrelation']).T
res






