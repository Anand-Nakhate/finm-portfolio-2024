import pandas as pd
import numpy as np
from tabulate import tabulate
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm


df_desc = pd.read_excel('../data/dfa_analysis_data.xlsx', sheet_name='descriptions')
df_factors = pd.read_excel('../data/dfa_analysis_data.xlsx', sheet_name='factors').set_index('Date')
df_portfolios = pd.read_excel('../data/dfa_analysis_data.xlsx', sheet_name='portfolios (total returns)').set_index('Date')


# 2
df_factors.head()


# 2.1
import pandas as pd

def calculate_univariate_performance_statistics(df, annualization_factor=1, quantile=0.05, periods=None):
    if periods is None:
        periods = [(df.index.min(), df.index.max())]
    
    summary_list = []

    for period in periods:
        start_date, end_date = period
        period_df = df.loc[start_date:end_date]
        
        summary_df = pd.DataFrame(index=period_df.columns)
        summary_df['Mean'] = period_df.mean() * annualization_factor
        summary_df['Volatility'] = period_df.std() * (annualization_factor ** 0.5)
        summary_df['Sharpe_ratio'] = summary_df['Mean'] / summary_df['Volatility']
        summary_df[f'VaR({quantile})'] = period_df.quantile(quantile, axis=0)
        
        start_year = pd.to_datetime(start_date).year
        end_year = pd.to_datetime(end_date).year
        summary_df['Period'] = f"{start_year}-{end_year}"
        
        summary_df = summary_df.reset_index().rename(columns={'index': 'Factor'}).set_index(['Period', 'Factor'])
        summary_list.append(summary_df)
    
    summary = pd.concat(summary_list)
    return summary



summary_statistics = calculate_univariate_performance_statistics(df_factors.drop(columns=['RF']), 12)
# print(tabulate(summary_statistics, headers=summary_statistics.columns, tablefmt="heavy_grid"))
summary_statistics


periods = [(df_factors.index.min(), '1980-12-31'), ('1981-01-01', '2001-12-31'), ('2002-01-01', df_factors.index.max())]
summary_statistics = calculate_univariate_performance_statistics(df_factors.drop(columns=['RF']), 12, periods=periods)
summary_statistics





# 2.3
def plot_correlation_matrix(df, title=None, max_min=False):
    fig, ax = plt.subplots(figsize=(8, 5))
    correlation_matrix = df.corr()
    sns.heatmap(correlation_matrix, 
                xticklabels=correlation_matrix.columns,
                yticklabels=correlation_matrix.columns, annot=True, ax=ax)
    if title:
        ax.set_title(title, fontsize=16)

    if max_min:
        corrs = correlation_matrix.unstack().sort_values().to_frame('Corr')
        corrs = corrs[corrs['Corr'] != 1]
        corrs_max = corrs.index[-1]
        corrs_min = corrs.index[0]
        print(f'Max Correlation pair is {corrs_max}')
        print(f'Min Correlation pair is {corrs_min}')

plot_correlation_matrix(df_factors.drop(columns=['RF']), title="Correlation Matrix for Full Period")
plot_correlation_matrix(df_factors.drop(columns=['RF']).loc[:'1980-12-31'], title="Correlation Matrix Till 1980")
plot_correlation_matrix(df_factors.drop(columns=['RF']).loc['1981-01-01':'2001-12-31'], title="Correlation Matrix for 1981-2001")
plot_correlation_matrix(df_factors.drop(columns=['RF']).loc['2002-01-01':], title="Correlation Matrix for 2002-Present")





# 2.4
def plot_cumulative_returns(df, period=None, title="Cumulative Returns of Factors"):
    if period is None:
        period = (df.index.min(), df.index.max())
    
    start_date, end_date = pd.to_datetime(period[0]), pd.to_datetime(period[1])
    sub_df = df.loc[start_date:end_date]
    cumulative_returns = (1 + sub_df).cumprod()
    
    plt.figure(figsize=(12, 6))
    
    for column in cumulative_returns.columns:
        plt.plot(cumulative_returns.index, cumulative_returns[column], label=f"{column} ({start_date.year}-{end_date.year})")

    plt.title(title)
    plt.xlabel("Date")
    plt.ylabel("Cumulative Return")
    plt.legend()
    plt.grid(True)
    plt.show()

plot_cumulative_returns(df_factors[['Mkt-RF', 'SMB', 'HML']])


plot_cumulative_returns(
    df_factors[['Mkt-RF', 'SMB', 'HML']],
    title="Cumulative Returns of Factors 1981-2001",
    period=('1981-01-01','2001-12-31')
)


plot_cumulative_returns(
    df_factors[['Mkt-RF', 'SMB', 'HML']],
    title="Cumulative Returns of Factors 2002-Present",
    period=('2002-01-01', df_factors.index.max())
)





# 3
df_excess_portfolios = df_portfolios.loc['1981-01-01':].sub(df_factors['RF'].loc['1981-01-01':], axis=0)
df_excess_portfolios


# 3.1
portfolio_summary = calculate_univariate_performance_statistics(df_excess_portfolios, 12)
portfolio_summary





import statsmodels.api as sm
import pandas as pd
import numpy as np

def capm_analysis(df_portfolios, df_market, annualization=1):
    alphas, treynor_ratios, information_ratios, r_squared = [], [], [], []
    betas_dict = {factor: [] for factor in df_market.columns} 

    for col in df_portfolios.columns:
        y = df_portfolios[col]
        X = sm.add_constant(df_market)
        model = sm.OLS(y, X, missing='drop').fit()
        
        alpha = model.params['const'] * annualization
        
        for factor in df_market.columns:
            betas_dict[factor].append(model.params.get(factor, np.nan))
        
        mean_excess_return = y.mean()
        primary_beta = model.params[df_market.columns[0]]
        treynor_ratio = mean_excess_return * annualization / primary_beta if primary_beta != 0 else np.nan

        expected_return = alpha + sum(model.params[factor] * df_market[factor].mean() for factor in df_market.columns)
        residual_std_dev = model.resid.std()
        
        information_ratio = model.params['const'] * (annualization)**0.5 / residual_std_dev if residual_std_dev != 0 else np.nan

        alphas.append(alpha)
        treynor_ratios.append(treynor_ratio)
        information_ratios.append(information_ratio)
        r_squared.append(model.rsquared)

    results_df = pd.DataFrame({
        'Alpha': alphas,
        'Treynor Ratio': treynor_ratios,
        'Information Ratio': information_ratios,
        'R-Squared': r_squared
    }, index=df_portfolios.columns)

    for factor, beta_values in betas_dict.items():
        results_df[f'Beta_{factor}'] = beta_values
    
    return results_df

results_df = capm_analysis(df_excess_portfolios, df_factors[['Mkt-RF']].loc['1981-01-01':], annualization=12)
results_df[['Alpha'] + [col for col in results_df.columns if col.startswith('Beta_')]]


# 3.2b 
mae = np.mean(np.abs(results_df['Alpha']))
print("\nMean Absolute Error (MAE):", mae)


# 3.2c
results_df[[col for col in results_df.columns if col.startswith('Beta_')] + ['Treynor Ratio', 'Information Ratio']]





# 3.3
capm_analysis(
    df_excess_portfolios.loc['1981-01-01':].mean().to_frame('Portfolio Mean Excess Returns'), 
    results_df[[col for col in results_df.columns if col.startswith('Beta_')]],
    12
)











# 4.1
def calculate_tangency_weights(df_excess_returns, annualization_factor=12):
    mu = df_excess_returns.mean() * annualization_factor
    cov_matrix = df_excess_returns.cov() * annualization_factor
    inv_cov_matrix = np.linalg.inv(cov_matrix)
    ones = np.ones(len(mu))
    scaling_factor = 1 / (ones.T @ inv_cov_matrix @ mu)
    tangency_weights = scaling_factor * (inv_cov_matrix @ mu)
    tangency_df = pd.DataFrame({
        'Asset': df_excess_returns.columns,
        'Weights': tangency_weights
    })
    net_benchmark = df_excess_returns @ tangency_weights
    net_benchmark_df = pd.DataFrame(index = df_excess_returns.index)
    net_benchmark_df['Tangency'] = net_benchmark
    return tangency_df, net_benchmark_df

tangency_weights, tangency_returns = calculate_tangency_weights(df_excess_portfolios, annualization_factor=12)
tangency_weights


results_tangency_df = capm_analysis(df_excess_portfolios, tangency_returns.loc['1981-01-01':], annualization=12)
# results_tangency_df[['Alpha'] + [col for col in results_tangency_df.columns if col.startswith('Beta_')]]


capm_analysis(
    df_excess_portfolios.loc['1981-01-01':].mean().to_frame('Portfolio Mean Excess Returns'), 
    results_tangency_df[[col for col in results_tangency_df.columns if col.startswith('Beta_')]],
    12
)


# 4.3
df_factors_excess = df_factors.drop(columns=['RF'])
results_multi_df = capm_analysis(df_excess_portfolios, df_factors_excess.loc['1981-01-01':], annualization=12)


capm_analysis(
    df_excess_portfolios.loc['1981-01-01':].mean().to_frame('Portfolio Mean Excess Returns'), 
    results_multi_df[[col for col in results_multi_df.columns if col.startswith('Beta_')]],
    12
)


# 4.3
import numpy as np
import pandas as pd
import statsmodels.api as sm
from scipy import stats

def calculate_H_statistic(portfolio_excess_returns, market_excess_return, annualization_factor=12, df=25):
    T = portfolio_excess_returns.shape[0]

    SR = market_excess_return.mean() * annualization_factor / (market_excess_return.std() * np.sqrt(annualization_factor))
    alphas = []
    residuals = []

    for col in portfolio_excess_returns.columns:
        y = portfolio_excess_returns[col]
        X = sm.add_constant(market_excess_return)
        model = sm.OLS(y, X, missing='drop').fit()
        
        alphas.append(model.params['const'] * annualization_factor)  # Annualized alpha
        residuals.append(model.resid)

    alpha_vector = np.array(alphas)

    resid_matrix = np.column_stack(residuals)
    Sigma = np.cov(resid_matrix, rowvar=False)
    Sigma_inv = pd.DataFrame(np.linalg.inv(Sigma), index=portfolio_excess_returns.columns, columns=portfolio_excess_returns.columns)

    H_statistic = T * (1 + SR ** 2) ** (-1) * (alpha_vector @ Sigma_inv @ alpha_vector)

    p_value = 1 - stats.chi2.cdf(H_statistic, df=df)
    return H_statistic, p_value

H_statistic, p_value = calculate_H_statistic(
    df_excess_portfolios.loc['1981-01-01':], 
   df_factors[['Mkt-RF']].loc['1981-01-01':])

print(f"H-Statistic: {H_statistic}")
print(f"p-value: {p_value}")






