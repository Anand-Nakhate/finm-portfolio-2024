import pandas as pd
import numpy as np
from tabulate import tabulate
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
from statsmodels.regression.rolling import RollingOLS
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


df_desc = pd.read_excel('../data/proshares_analysis_data.xlsx', sheet_name='descriptions')
df_hedge_fund = pd.read_excel('../data/proshares_analysis_data.xlsx', sheet_name='hedge_fund_series').rename(columns={'Unnamed: 0':'Date'}).set_index('Date')
df_merrill_factors = pd.read_excel('../data/proshares_analysis_data.xlsx', sheet_name='merrill_factors').rename(columns={'Unnamed: 0':'Date'}).set_index('Date')
df_other = pd.read_excel('../data/proshares_analysis_data.xlsx', sheet_name='other_data')


# 2
def calculate_return_statistics(df, annualization_factor=1):
    summary_df = pd.DataFrame(index = df.columns)
    summary_df['Mean'] = df.mean() * annualization_factor
    summary_df['Volatility'] = df.std() * (annualization_factor ** 0.5)
    summary_df['Sharpe_ratio'] = summary_df['Mean'] / summary_df['Volatility'] 
    return summary_df
    
# 2.1
summary_statistics = calculate_return_statistics(df_hedge_fund, 12)
print(tabulate(summary_statistics, headers=summary_statistics.columns, tablefmt="heavy_grid"))


# 2.2
def calculate_max_drawdown(df):
    drawdown_df = pd.DataFrame(index=df.columns)
    cumulative_returns = (1+df).cumprod()
    rolling_max = cumulative_returns.cummax()
    curr_drawdown = (cumulative_returns - rolling_max) / rolling_max
    max_drawdown = curr_drawdown.min()
    date_max_drawdown = curr_drawdown.idxmin()
    drawdown_df['Max Drawdown'] = max_drawdown
    drawdown_df['Bottom'] = date_max_drawdown

    for col in df.columns:
        drawdown_df.loc[col, 'Peak'] = pd.to_datetime((rolling_max.loc[:date_max_drawdown[col], col]).idxmax())
        recovery_df = (curr_drawdown.loc[date_max_drawdown[col]:, col])
        try:
            drawdown_df.loc[col, 'Recovery'] = pd.to_datetime(recovery_df[recovery_df >=0].index[0])
        except:
            drawdown_df.loc[col, 'Recovery'] = pd.to_datetime(None)
    try:
        drawdown_df['Time To Recover'] = (drawdown_df['Recovery'] - drawdown_df['Bottom'])
    except:
        drawdown_df['Time To Recover'] = None
    return drawdown_df
    
def calculate_taik_risk_statistics(df, quantile=0.05):
    summary_df = pd.DataFrame(index=df.columns)
    summary_df['Skewness'] = df.skew()
    summary_df['Excess Kurtosis'] = df.kurt()-3
    summary_df[f'VaR({quantile})'] = df.quantile(0.05, axis=0)
    summary_df[f'CVaR({quantile})'] = df[df.le(df.quantile(0.05, axis=0))].mean()
    summary_df['Max'] = df.max()
    summary_df['Min'] = df.min()
    summary_df = summary_df.join(calculate_max_drawdown(df))
    return summary_df

tail_risk_statistics = calculate_taik_risk_statistics(df_hedge_fund)
tail_risk_statistics


# 2.3
def get_regression_statistics(X, Y, annualization = 1, error_variance=False):
    if not isinstance(X, pd.DataFrame):
        X = X.to_frame()
    if not isinstance(Y, pd.DataFrame):
        Y = Y.to_frame()
    df = Y.join(X, how='inner')
    Y = df[Y.columns]
    X = df[X.columns]

    regression_df = pd.DataFrame(index = Y.columns)
    for col in Y.columns:
        y = Y[col]
    
        model = LinearRegression().fit(X, y)
        regression_df.loc[col, 'Alpha (Intercept)'] = model.intercept_ * annualization
        regression_df.loc[col, X.columns + " (Beta)"] = model.coef_
        regression_df.loc[col, 'R-squared'] = model.score(X, y)

        y_fit = model.predict(X)
        residuals = y - y_fit

        if error_variance:
            print(f"Volatility of Residuals: {np.std(residuals, ddof=1)}")
        
        # Treynor Ratio
        if X.shape[1] == 1:
            try:
                regression_df.loc[col, 'Treynor Ratio'] = (y.mean()/model.coef_)*annualization
            except:
                regression_df.loc[col, 'Treynor Ratio'] = None
        
        # Information Ratio
        try:
            regression_df.loc[col, 'Information Ratio'] = (model.intercept_ / residuals.std()) * (annualization)**0.5
        except:
            regression_df.loc[col, 'Information Ratio'] = None
            
    return regression_df

regression_results = get_regression_statistics(df_merrill_factors['SPY US Equity'],df_hedge_fund,annualization=12)
print(tabulate(regression_results, headers=regression_results.columns, tablefmt="heavy_grid"))





# 2.5
def plot_correlation_matrix(df, max_min=True):
    fig, ax = plt.subplots(figsize=(8,5))
    correlation_matrix = df.corr()
    sns.heatmap(correlation_matrix, 
            xticklabels=correlation_matrix.columns,
            yticklabels=correlation_matrix.columns, annot=True)
    
    corrs = correlation_matrix.unstack().sort_values().to_frame('Corr')
    corrs = corrs[corrs['Corr']!=1]
    corrs_max = corrs.index[-1]
    corrs_min = corrs.index[0]
    
    print(f'Max Correlation pair is {corrs_max}')
    print(f'Min Correlation pair is {corrs_min}')
plot_correlation_matrix(df_hedge_fund)


# 2.6
X = df_merrill_factors
y = df_hedge_fund['HFRIFWI Index']
regression_results = get_regression_statistics(X,y,annualization=12, error_variance=True).T
print(tabulate(regression_results, headers=regression_results.columns, tablefmt="heavy_grid"))
print("The Beta's are relatively small, suggesting realistic position sizes rather than requiring huge long-short positions.")


#2.7
y = df_hedge_fund['HFRIFWI Index']
X = sm.add_constant(df_merrill_factors)
model = RollingOLS(y,X,window=60)
rolling_betas = model.fit().params
rolling_betas.tail()


Rolling_IS_prediction = (rolling_betas * X).sum(axis=1,skipna=False)
Rolling_OOS_prediction = (rolling_betas.shift() * X).sum(axis=1,skipna=False)
replication = df_hedge_fund[['HFRIFWI Index']].copy()

y = df_hedge_fund['HFRIFWI Index']
X = sm.add_constant(df_merrill_factors)
static_model = sm.OLS(y,X).fit()
print(static_model.summary())

replication['Static-IS-Prediction'] = static_model.fittedvalues
replication['Rolling-IS-Prediction'] = Rolling_IS_prediction
replication['Rolling-OOS-Prediction'] = Rolling_OOS_prediction
replication.tail()


# Performance of Rolling Replication:

rolling_oos_pred_df = replication.dropna(subset=['HFRIFWI Index', 'Rolling-OOS-Prediction'])
y_actual = rolling_oos_pred_df['HFRIFWI Index']
y_pred_oos = rolling_oos_pred_df['Rolling-OOS-Prediction']

mse_oos = mean_squared_error(y_actual, y_pred_oos)
rmse_oos = np.sqrt(mse_oos)
mae_oos = mean_absolute_error(y_actual, y_pred_oos)
r2_oos = r2_score(y_actual, y_pred_oos)
correlation_oos = np.corrcoef(y_actual, y_pred_oos)[0, 1]

print(f"Out-of-Sample Performance:")
print(f"Actual Mean: {y_actual.mean()} Fitted Mean: {y_pred_oos.mean()}")
print(f"MSE: {mse_oos}")
print(f"RMSE: {rmse_oos}")
print(f"MAE: {mae_oos}")
print(f"R-squared: {r2_oos}")
print(f"Correlation: {correlation_oos}")





# 2.8
y = df_hedge_fund['HFRIFWI Index']
X_no_int = df_merrill_factors
static_model_noint = sm.OLS(y,X_no_int).fit()
print(static_model_noint.summary())
betas = pd.DataFrame(static_model.params,columns=['With Intercept']).T
betas.loc['Without Intercept'] = static_model_noint.params
print(tabulate(betas, headers=betas.columns, tablefmt="heavy_grid"))


# Note: Adding Rolling OLS without intercept (For Comparision)
model = RollingOLS(y,X_no_int,window=60)
rolling_betas_no_int = model.fit().params
Rolling_IS_prediction_no_intercept = (rolling_betas_no_int * X_no_int).sum(axis=1,skipna=False)
Rolling_OOS_prediction_no_intercept = (rolling_betas_no_int.shift() * X_no_int).sum(axis=1,skipna=False)
rolling_betas.tail()


replication['Static-IS-Prediction-No_Intercept'] = static_model_noint.fittedvalues
replication['Rolling-IS-Prediction-No_Intercept'] = Rolling_IS_prediction_no_intercept
replication['Rolling-OOS-Prediction-No_Intercept'] = Rolling_OOS_prediction_no_intercept
replication.tail()



print(f"Mean Static Insample Prediction with Intercept: {replication['Static-IS-Prediction'].mean()}")
print(f"Mean Static Insample Prediction without Intercept: {replication['Static-IS-Prediction-No_Intercept'].mean()}")
print(f"Mean Actual: {replication['HFRIFWI Index'].mean()}\n")

print(f"Correlation Static Insample Prediction with Intercept and Actual: {np.corrcoef(replication['HFRIFWI Index'], replication['Static-IS-Prediction'])[0, 1]}")
print(f"Correlation Static Insample Prediction without Intercept and Actual: {np.corrcoef(replication['HFRIFWI Index'], replication['Static-IS-Prediction-No_Intercept'])[0, 1]}")
print(tabulate(betas, headers=betas.columns, tablefmt="heavy_grid"))





rolling_oos_pred_noint_df = replication.dropna(subset=['HFRIFWI Index', 'Rolling-OOS-Prediction-No_Intercept'])
y_actual = rolling_oos_pred_noint_df['HFRIFWI Index']
y_pred_oos = rolling_oos_pred_noint_df['Rolling-OOS-Prediction-No_Intercept']

mse_oos = mean_squared_error(y_actual, y_pred_oos)
rmse_oos = np.sqrt(mse_oos)
mae_oos = mean_absolute_error(y_actual, y_pred_oos)
r2_oos = r2_score(y_actual, y_pred_oos)
correlation_oos = np.corrcoef(y_actual, y_pred_oos)[0, 1]

print(f"Out-of-Sample Performance (No Intercept):")
print(f"Actual Mean: {y_actual.mean()} Fitted Mean: {y_pred_oos.mean()}")
print(f"MSE: {mse_oos}")
print(f"RMSE: {rmse_oos}")
print(f"MAE: {mae_oos}")
print(f"R-squared: {r2_oos}")
print(f"Correlation: {correlation_oos}")









