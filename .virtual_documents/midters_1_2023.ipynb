import pandas as pd
import numpy as np
import midterm1_helper as mh
import matplotlib.pyplot as plt
import re
import cmds.portfolio_management_helper as pmh


df_info = pd.read_excel('data/midterm_1_data_2023.xlsx',sheet_name='info')
df_excess_returns = pd.read_excel('data/midterm_1_data_2023.xlsx',sheet_name='excess returns')
df_spy = pd.read_excel('data/midterm_1_data_2023.xlsx',sheet_name='spy')


df_excess_returns = df_excess_returns.rename(columns={'date':'Date'})
df_excess_returns.set_index('Date', inplace=True)
df_excess_returns.head()


pmh.calc_summary_statistics(
    df_excess_returns,
    annual_factor=52,
    provided_excess_returns=True,
    keep_columns=['Annualized Vol', 'Annualized Mean', 'Annualized Sharpe']
)


def performance_summary(return_data, annualization = 12):
    """ 
        Returns the Performance Stats for given set of returns
        Inputs: 
            return_data - DataFrame with Date index and Monthly Returns for different assets/strategies.
        Output:
            summary_stats - DataFrame with annualized mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and
                            CVaR (0.5) and drawdown based on monthly returns. 
    """
    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*annualization)
    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(annualization))
    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']
    
    summary_stats['Skewness'] = return_data.skew()
    summary_stats['Excess Kurtosis'] = return_data.kurtosis()
    summary_stats['VaR (0.05)'] = return_data.quantile(.05, axis = 0)
    summary_stats['CVaR (0.05)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()
    summary_stats['Min'] = return_data.min()
    summary_stats['Max'] = return_data.max()
    
    wealth_index = 1000*(1+return_data).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/previous_peaks

    summary_stats['Max Drawdown'] = drawdowns.min()
    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]
    summary_stats['Bottom'] = drawdowns.idxmin()
    
    recovery_date = []
    for col in wealth_index.columns:
        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()
        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T
        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())
    summary_stats['Recovery'] = recovery_date
    
    return summary_stats


performance_summary(df_excess_returns, 52)


tangency = pmh.calc_tangency_weights(df_excess_returns)
tangency


pmh.calc_summary_statistics(
    pmh.calc_tangency_weights(df_excess_returns, return_port_ret = True),
    annual_factor=52,
    provided_excess_returns=True,
    keep_columns=['Annualized Vol', 'Annualized Mean', 'Annualized Sharpe']
)


best_worst_sharpe=(
    pmh.calc_summary_statistics(
        df_excess_returns,
        annual_factor=52,
        provided_excess_returns=True,
        keep_columns=['Annualized Sharpe']
    )
    .sort_values("Annualized Sharpe")
    .reset_index()
    .loc[lambda df: df.index.isin([0, len(df.index)-1])]
    .rename(columns={"index": "Asset"})
    .assign(Label=["Worst Sharpe", "Best Sharpe"])
)
best_worst_sharpe


tangency.loc[best_worst_sharpe.loc[0, 'Asset']]


tangency.loc[best_worst_sharpe.loc[6, 'Asset']]


portfolio_tangency = pmh.calc_tangency_weights(df_excess_returns.loc[:'2022-12-30'])
portfolio_tangency


n_assets = len(df_excess_returns.columns)
EW_portfolio = pd.DataFrame(index = df_excess_returns.columns)
EW_portfolio.loc[:, 'EW Weights'] = 1/n_assets
EW_portfolio


df_variance_dict = df_excess_returns.std().map(lambda x: x ** 2).to_dict()
df_inv_variance_dict = {asset: 1 / variance for asset, variance in df_variance_dict.items()}
RP_portfolio = pd.DataFrame(index = df_excess_returns.columns)
for col in df_variance_dict:
    RP_portfolio.loc[col, 'EW Weights'] = df_variance_dict[col]
RP_portfolio


Reg_Portfolio = pmh.calc_tangency_weights(df_excess_returns, return_port_ret=True, cov_mat=1/3, name="Regularized")
Reg_Portfolio



EW_portfolio.T @ df_excess_returns.mean(),


IN_SAMPLE_END_DATE = "'2022-12-30'"
OUT_OF_SAMPLE_START_DATE = "2023-01-06"

in_sample_assets_excess_returns = df_excess_returns.loc[:IN_SAMPLE_END_DATE]
out_of_sample_assets_excess_returns = df_excess_returns.loc[OUT_OF_SAMPLE_START_DATE:]


n_assets = len(df_excess_returns.columns)

# Equal Weights
in_sample_weights_equal = pd.DataFrame(
    data=[[1 / n_assets] for _ in range(n_assets)],
    columns=["Equal Weights"],
    index=in_sample_assets_excess_returns.columns
)
in_sample_weights_equal


# Risk Parity
in_sample_asset_variance_dict = in_sample_assets_excess_returns.std().map(lambda x: x ** 2).to_dict()
in_sample_asset_inv_variance_dict = {asset: 1 / variance for asset, variance in in_sample_asset_variance_dict.items()}
in_sample_weights_risk_parity = pd.DataFrame(in_sample_asset_inv_variance_dict, index=["Risk Parity Weights"]).transpose()
in_sample_weights_risk_parity


in_sample_weights_regularized = pmh.calc_tangency_weights(in_sample_assets_excess_returns, cov_mat=1/3, name="Regularized")
in_sample_weights_regularized



in_sample_weights_tangency = pmh.calc_tangency_weights(in_sample_assets_excess_returns)
in_sample_weights_tangency


in_sample_weights = (
    pd.concat([
        in_sample_weights_regularized,
        in_sample_weights_tangency,
        in_sample_weights_risk_parity,
        in_sample_weights_equal
    ], axis=1)
    .fillna(0)
)

in_sample_weights_scaled = in_sample_weights
in_sample_weights_scaled


(   
    pmh.calc_summary_statistics(
        in_sample_assets_excess_returns @ in_sample_weights_scaled,
        annual_factor=12,
        provided_excess_returns=True,
        keep_columns=['Annualized mean', 'Annualized vol', 'Annualized sharpe']
    )
    .sort_values('Annualized Sharpe', ascending=False)
)


(
    pmh.calc_summary_statistics(
        out_of_sample_assets_excess_returns @ in_sample_weights_scaled,
        annual_factor=12,
        provided_excess_returns=True,
        keep_columns=['annualized mean', 'annualized vol', 'annualized sharpe']
    )
    .sort_values('Annualized Sharpe', ascending=False)
)



