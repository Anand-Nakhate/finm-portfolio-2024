{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559895d2",
   "metadata": {},
   "source": [
    "# Midterm 2\n",
    "\n",
    "## FINM 36700 - 2024\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cde8d3",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc273c1a",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 2` assignment on Canvas, where you downloaded this. \n",
    "* Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers.)\n",
    "* Your submission should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo - you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f27b1",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_2_data.xlsx`\n",
    "\n",
    "This file contains the following sheets:\n",
    "- for Section 2:\n",
    "    * `sector stocks excess returns` - MONTHLY excess returns for 49 sector stocks\n",
    "    * `factors excess returns` - MONTHLY excess returns of AQR factor model from Homework 5\n",
    "- for Section 3:\n",
    "    * `factors excess returns` - MONTHLY excess returns of AQR factor model from Homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ff22ee-d2f0-4a80-8220-fe75191542bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4062fdd7-7017-4267-b93f-4cd45024c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector = pd.read_excel('../data/midterm_2_data.xlsx', sheet_name='sector excess returns').set_index('date')\n",
    "df_factors = pd.read_excel('../data/midterm_2_data.xlsx', sheet_name='factors excess returns').set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f799242c-e742-48d0-a3cb-9cb02037f26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agric</th>\n",
       "      <th>Food</th>\n",
       "      <th>Soda</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Toys</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>...</th>\n",
       "      <th>Boxes</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Whlsl</th>\n",
       "      <th>Rtail</th>\n",
       "      <th>Meals</th>\n",
       "      <th>Banks</th>\n",
       "      <th>Insur</th>\n",
       "      <th>RlEst</th>\n",
       "      <th>Fin</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>-0.0966</td>\n",
       "      <td>-0.0322</td>\n",
       "      <td>-0.0569</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0521</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>-0.0555</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0541</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>-0.0639</td>\n",
       "      <td>-0.0652</td>\n",
       "      <td>-0.0854</td>\n",
       "      <td>-0.0959</td>\n",
       "      <td>-0.0347</td>\n",
       "      <td>-0.0282</td>\n",
       "      <td>-0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.2224</td>\n",
       "      <td>-0.1119</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.1469</td>\n",
       "      <td>-0.0193</td>\n",
       "      <td>-0.1271</td>\n",
       "      <td>-0.0826</td>\n",
       "      <td>-0.1237</td>\n",
       "      <td>-0.0566</td>\n",
       "      <td>-0.0668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0819</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>-0.1098</td>\n",
       "      <td>-0.0906</td>\n",
       "      <td>-0.1449</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>-0.0880</td>\n",
       "      <td>-0.2451</td>\n",
       "      <td>-0.1254</td>\n",
       "      <td>-0.1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>-0.0529</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Agric   Food    Soda    Beer    Smoke   Toys    Fun     Books  \\\n",
       "date                                                                         \n",
       "1980-01-01 -0.0076  0.0285  0.0084  0.1009 -0.0143  0.1002  0.0362  0.0323   \n",
       "1980-02-01  0.0105 -0.0608 -0.0966 -0.0322 -0.0569 -0.0323 -0.0521 -0.0800   \n",
       "1980-03-01 -0.2224 -0.1119 -0.0167 -0.1469 -0.0193 -0.1271 -0.0826 -0.1237   \n",
       "1980-04-01  0.0449  0.0766  0.0232  0.0321  0.0830 -0.0529  0.0783  0.0153   \n",
       "1980-05-01  0.0632  0.0793  0.0457  0.0863  0.0815  0.0509  0.0324  0.0886   \n",
       "\n",
       "             Hshld   Clths  ...   Boxes   Trans   Whlsl   Rtail   Meals  \\\n",
       "date                        ...                                           \n",
       "1980-01-01  0.0048  0.0059  ...  0.0158  0.0875  0.0465 -0.0126  0.0430   \n",
       "1980-02-01 -0.0555 -0.0167  ... -0.0079 -0.0541 -0.0346 -0.0639 -0.0652   \n",
       "1980-03-01 -0.0566 -0.0668  ... -0.0819 -0.1509 -0.1098 -0.0906 -0.1449   \n",
       "1980-04-01  0.0304  0.0115  ...  0.0420 -0.0103 -0.0312  0.0353  0.0542   \n",
       "1980-05-01  0.0560  0.0098  ...  0.0564  0.1063  0.1142  0.0877  0.1134   \n",
       "\n",
       "             Banks   Insur   RlEst   Fin     Other  \n",
       "date                                                \n",
       "1980-01-01 -0.0283  0.0258  0.0768  0.0308  0.0669  \n",
       "1980-02-01 -0.0854 -0.0959 -0.0347 -0.0282 -0.0274  \n",
       "1980-03-01 -0.0560 -0.0880 -0.2451 -0.1254 -0.1726  \n",
       "1980-04-01  0.0728  0.0530  0.0977  0.0447  0.0769  \n",
       "1980-05-01  0.0578  0.0557  0.0915  0.0844  0.0685  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615d6ab6-59c2-4d41-bb6e-d92ce210cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0170</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>-0.0122</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.1290</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>-0.0955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0210</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MKT     HML     RMW     UMD\n",
       "date                                      \n",
       "1980-01-01  0.0551  0.0175 -0.0170  0.0755\n",
       "1980-02-01 -0.0122  0.0061  0.0004  0.0788\n",
       "1980-03-01 -0.1290 -0.0101  0.0146 -0.0955\n",
       "1980-04-01  0.0397  0.0106 -0.0210 -0.0043\n",
       "1980-05-01  0.0526  0.0038  0.0034 -0.0112"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6e066",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 25     |\n",
    "| 2       | 40     |\n",
    "| 3       | 35     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2fc26",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points unless otherwise specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81156e8f",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf4bc8",
   "metadata": {},
   "source": [
    "#### No Data Needed\n",
    "\n",
    "These problems do not require any data file. Rather, analyze them conceptually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2ec27",
   "metadata": {},
   "source": [
    "### 1.1.\n",
    "\n",
    "Historically, which pricing factor among the ones we studied has shown a considerable decrease in importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9479817-50bb-4f6c-af7f-5fa2f6813ab5",
   "metadata": {},
   "source": [
    "- Historically, the Size factor in the Fama-French model has shown a significant decrease in importance over time.\n",
    "- Initially, the size effectâ€”where small-cap stocks tend to outperform large-cap stocks was recognized. Some research and case studies we used in class, including studies by DFA, indicated that small-cap stocks historically provided excess returns over large-cap stocks, likely due to higher risk or market inefficiencies.\n",
    "- However, in recent years, the size factorâ€™s relevance has diminished for several reasons:\n",
    "- - Market Maturity\n",
    "- - Investor Behavior\n",
    "- - Empirical Evidence: Its significance has weakened in more recent data (Ex: from HW 4, 5)\n",
    "- This evolution reflects the changing dynamics in asset pricing and has led some investors and academics to reconsider the weighting or inclusion of the size factor in multifactor models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c8109",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.2.\n",
    "\n",
    "True or False: For a given factor model and a set of test assets, the addition of one more factor to that model will surely decrease the cross-sectional MAE. \n",
    "\n",
    "True or False: For a given factor model and a set of test assets, the addition of one more factor to that model will surely decrease the time-series MAE. \n",
    "\n",
    "Along with stating T/F, explain your reasoning for the two statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330af1a7-4b7a-4d15-bfe5-693aab884bd5",
   "metadata": {},
   "source": [
    " - 1 - False:\n",
    " - If the new factor doesn't explain additional cross-sectional variation, MAE may not decrease.\n",
    " - Introducing unnecessary factors can capture noise. May increase MAE.\n",
    "- Highly correlated factors can reduce the model's explanatory power.\n",
    " - 2 - False:\n",
    " - An irrelevant factor can introduce additional noise into time-series predictions.\n",
    " - More complex models are not inherently better and can perform worse out-of-sample.\n",
    " - Additional factors can make the model more sensitive to estimation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c00026",
   "metadata": {},
   "source": [
    "### 1.3.\n",
    "\n",
    "Consider the scenario in which you are helping two people with investments.\n",
    "\n",
    "* The young person has a 50 year investment horizon.\n",
    "* The elderly person has a 10 year investment horizon.\n",
    "* Both individuals have the same portfolio holdings.\n",
    "\n",
    "State who has the more certain cumulative return and explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3ca5b-3c99-4dc8-9c7e-96075e94eedf",
   "metadata": {},
   "source": [
    "- The elderly person has more certain cumulative returns over their 10-year horizon.\n",
    "- Longer horizons lead to greater total volatility, despite lower annualized volatility.\n",
    "- While the average annual return may become more predictable over time, the cumulative return becomes less certain due to compounding volatility.\n",
    "- Probability of Averages increases the chance of encountering adverse market conditions.\n",
    "- More time allows for greater divergence from expected outcomes.\n",
    "- Shorter Horizons Offer Greater Certainty: The elderly person faces less cumulative risk over 10 years, making their cumulative returns more predictable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d4d72",
   "metadata": {},
   "source": [
    "### 1.4.\n",
    "\n",
    "Suppose we find that the 10-year bond yield works well as a new pricing factor, along with `MKT`.\n",
    "\n",
    "Consider two ways of building this new factor.\n",
    "1. Directly use the index of 10-year yields, `YLD`\n",
    "1. Construct a Fama-French style portfolio of equities, `FFYLD`. (Rank all the stocks by their correlation to bond yield changes, and go long the highest ranked and shor tthe lowest ranked.)\n",
    "\n",
    "Could you test the model with `YLD` and the model with `FFYLD` in the exact same ways? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf4d96-27fa-4b9e-972f-98ed84e1247b",
   "metadata": {},
   "source": [
    "- No, YLD and FFYLD require different testing approaches.\n",
    "- YLD (bond yield) is an economic indicator, suited for cross-sectional analysis to assess its impact across stocks, as itâ€™s not a return factor.\n",
    "- FFYLD (a return-based factor) fits traditional multifactor testing, allowing both time-series and cross-sectional analysis.\n",
    "- YLDâ€™s non-return nature demands a unique approach, while FFYLD aligns with standard factor model methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2d238",
   "metadata": {},
   "source": [
    "### 1.5.\n",
    "\n",
    "Suppose we implement a momentum strategy on cryptocurrencies rather than US stocks.\n",
    "\n",
    "Conceptually speaking, but specific to the context of our course discussion, how would the risk profile differ from the momentum strategy of US equities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0b094-eb02-4393-9528-abac7eb21010",
   "metadata": {},
   "source": [
    "- A momentum strategy on cryptocurrencies would carry a much higher risk profile than US equities due to:\n",
    "- Cryptocurrency prices fluctuate more drastically, amplifying momentum risks, i.e., high volatility.\n",
    "- Thin market depth means trades can heavily impact prices, increasing execution risk, i.e., low liquidity.\n",
    "- Regulatory and Structural Risks: Less oversight and potential for price manipulation heighten systemic riskâ€‹ (Ex, From Barnstable Case).\n",
    "- In essence, crypto momentum strategies face amplified volatility, liquidity, and structural challenges compared to US equities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ce7d4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8a354",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Pricing and Tangency Portfolio\n",
    "\n",
    "You work in a hedge fund that believes that the AQR 4-Factor Model (present in Homework 5) is the perfect pricing model for stocks.\n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\left[ \\tilde{r}^i \\right] = \\beta^{i,\\text{MKT}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{MKT}} \\right] + \\beta^{i,\\text{HML}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{HML}} \\right] + \\beta^{i,\\text{RMW}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{RMW}} \\right] + \\beta^{i,\\text{UMD}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{UMD}} \\right]\n",
    "$$\n",
    "\n",
    "The factors are available in the sheet `factors excess returns`.\n",
    "\n",
    "The hedge fund invests in sector-tracking ETFs available in the sheet `sectors excess returns`. You are to allocate into these sectors according to a mean-variance optimization with...\n",
    "\n",
    "* regularization: elements outside the diagonal covariance matrix divided by 2.\n",
    "* modeled risk premia: expected excess returns given by the factor model rather than just using the historic sample averages.\n",
    "\n",
    "You are to train the portfolio and test out-of-sample. The timeframes should be:\n",
    "* Training timeframe: Jan-2018 to Dec-2022.\n",
    "* Testing timeframe: Jan-2023 to most recent observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909951db-2886-40fe-8d36-6540ac28c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = '2018-01-01', '2022-12-01'\n",
    "test_start, test_end = '2023-01-01', min(df_factors.index.max(), df_sector.index.max())\n",
    "df_sector_train = df_sector.loc[train_start:train_end]\n",
    "df_factors_train = df_factors.loc[train_start:train_end]\n",
    "df_sector_test = df_sector.loc[test_start:test_end]\n",
    "df_factors_test = df_factors.loc[test_start:test_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db465bc9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1.\n",
    "(8pts)\n",
    "\n",
    "Calculate the model-implied expected excess returns of every asset.\n",
    "\n",
    "The time-series estimations should...\n",
    "* NOT include an intercept. (You assume the model holds perfectly.)\n",
    "* use data from the `training` timeframe.\n",
    "\n",
    "With the time-series estimates, use the `training` timeframe's sample average of the factors as the factor premia. Together, this will give you the model-implied risk premia, which we label as\n",
    "$$\n",
    "\\lambda_i := \\mathbb{E}[\\tilde{r}_i]\n",
    "$$\n",
    "\n",
    "* Store $\\lambda_i$ and $\\boldsymbol{\\beta}^i$ for each asset.\n",
    "* Print $\\lambda_i$ for `Agric`, `Food`, `Soda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23502c5e-6fe5-44aa-a744-bcf97b558dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agric: \n",
      "Î» = 0.003655102106916498, \n",
      "Î² = MKT    0.832362\n",
      "HML    0.556541\n",
      "RMW   -0.502093\n",
      "UMD    0.038972\n",
      "dtype: float64\n",
      "\n",
      "Food : \n",
      "Î» = 0.005454267868380435, \n",
      "Î² = MKT    0.524509\n",
      "HML    0.205452\n",
      "RMW    0.309711\n",
      "UMD   -0.003572\n",
      "dtype: float64\n",
      "\n",
      "Soda : \n",
      "Î» = 0.007336244651963076, \n",
      "Î² = MKT    0.540240\n",
      "HML    0.179127\n",
      "RMW    0.638443\n",
      "UMD    0.013688\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: The dataset has an additional space after Food and Soda in column names\n",
    "factor_premia = df_factors_train.mean()\n",
    "\n",
    "expected_excess_returns = {}\n",
    "betas = {}\n",
    "\n",
    "for asset in df_sector_train.columns:\n",
    "    X = df_factors_train[['MKT', 'HML', 'RMW', 'UMD']]\n",
    "    y = df_sector_train[asset]\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    betas[asset] = model.params\n",
    "\n",
    "    lambda_i = model.params @ factor_premia.values\n",
    "    expected_excess_returns[asset] = lambda_i\n",
    "\n",
    "for asset in ['Agric', 'Food ', 'Soda ']:\n",
    "    print(f\"{asset}: \\nÎ» = {expected_excess_returns[asset]}, \\nÎ² = {betas[asset]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80c6b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2.\n",
    "\n",
    "Use the expected excess returns derived from (2.1) with the **regularized** covariance matrix to calculate the weights of the tangency portfolio.\n",
    "\n",
    "- Use the covariance matrix only for `training` timeframe.\n",
    "- Calculate and store the vector of weights for all the assets.\n",
    "- Return the weights of the tangency portfolio for `Agric`, `Food`, `Soda`.\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t} = \\dfrac{\\tilde{\\Sigma}^{-1} \\bm{\\lambda}}{\\bm{1}' \\tilde{\\Sigma}^{-1} \\bm{\\lambda}}\n",
    "$$\n",
    "\n",
    "Where $\\tilde{\\Sigma}^{-1}$ is the regularized covariance-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f5803c-9071-496d-9318-e6e1f8a8d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agric: -0.030722716601690035\n",
      "Food : 0.01532022454483564\n",
      "Soda : 0.13294447809892707\n"
     ]
    }
   ],
   "source": [
    "# Note: Using the training sample for the calculations.\n",
    "lambda_vector = np.array(list(expected_excess_returns.values()))\n",
    "\n",
    "cov_matrix = df_sector_train.cov()\n",
    "diag_cov = np.diag(np.diag(cov_matrix)) \n",
    "reg_cov = (cov_matrix + diag_cov) / 2  \n",
    "inv_reg_cov = np.linalg.inv(reg_cov)\n",
    "\n",
    "ones = np.ones(len(lambda_vector))\n",
    "scaling_factor_reg = 1 / (ones.T @ inv_reg_cov @ lambda_vector)\n",
    "reg_weights = scaling_factor_reg * (inv_reg_cov @ lambda_vector)\n",
    "\n",
    "assets = df_sector_train.columns\n",
    "weights_dict = dict(zip(assets, reg_weights))\n",
    "\n",
    "for asset in ['Agric', 'Food ', 'Soda ']:\n",
    "    print(f\"{asset}: {weights_dict[asset]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c171c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.3.\n",
    "\n",
    "Evaluate the performance of this allocation in the `testing` period. Report the **annualized**\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fac775-89bb-4f7d-9b59-a9571ee012e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.181176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.119549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpe</th>\n",
       "      <td>1.515494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "mean    0.181176\n",
       "vol     0.119549\n",
       "sharpe  1.515494"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_returns = df_sector_test @ reg_weights  \n",
    "def calculate_univariate_statistics(df, annual_factor=12):\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "\n",
    "    mean_return = df.mean() * annual_factor\n",
    "    volatility = df.std() * np.sqrt(annual_factor)\n",
    "    sharpe_ratio = mean_return / volatility\n",
    "\n",
    "    stats_df = pd.DataFrame({\n",
    "        'mean': mean_return,\n",
    "        'vol': volatility,\n",
    "        'sharpe': sharpe_ratio\n",
    "    })\n",
    "\n",
    "    return stats_df.T\n",
    "calculate_univariate_statistics(test_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6f8bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.4.\n",
    "\n",
    "(7pts)\n",
    "\n",
    "Construct the same tangency portfolio as in `2.2` but with one change:\n",
    "* replace the risk premia of the assets, (denoted $\\lambda_i$) with the sample averages of the excess returns from the `training` set.\n",
    "\n",
    "So instead of using $\\lambda_i$ suggested by the factor model (as in `2.1-2.3`) you're using sample averages for $\\lambda_i$.\n",
    "\n",
    "- Return the weights of the tangency portfolio for `Agric`, `Food`, `Soda`.\n",
    "\n",
    "Evaluate the performance of this allocation in the `testing` period. Report the **annualized**\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076e2f90-fba1-4d9e-99e9-f1e8213251f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agric: 0.14408986452043415\n",
      "Food : -0.06980957545009533\n",
      "Soda : 0.32267987966472\n"
     ]
    }
   ],
   "source": [
    "sample_excess_returns = df_sector.loc[train_start:train_end].mean()\n",
    "\n",
    "cov_matrix = df_sector.loc[train_start:train_end].cov()\n",
    "diag_cov = np.diag(np.diag(cov_matrix))\n",
    "reg_cov = (cov_matrix + diag_cov) / 2\n",
    "inv_reg_cov = np.linalg.inv(reg_cov)\n",
    "\n",
    "ones = np.ones(len(sample_excess_returns))\n",
    "scaling_factor = 1 / (ones.T @ inv_reg_cov @ sample_excess_returns.values)\n",
    "reg_weights = scaling_factor * (inv_reg_cov @ sample_excess_returns.values)\n",
    "\n",
    "assets = df_sector.columns\n",
    "weights_dict = dict(zip(assets, reg_weights))\n",
    "\n",
    "for asset in ['Agric', 'Food ', 'Soda ']:\n",
    "    print(f\"{asset}: {weights_dict[asset]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f714bf74-8224-453c-858f-2502cbef28c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.176801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.153010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpe</th>\n",
       "      <td>1.155487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "mean    0.176801\n",
       "vol     0.153010\n",
       "sharpe  1.155487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sector_test = df_sector.loc[test_start:test_end]\n",
    "portfolio_returns = df_sector_test @ reg_weights\n",
    "\n",
    "calculate_univariate_statistics(portfolio_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172cbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.5.\n",
    "\n",
    "Which allocation performed better in the `testing` period: the allocation based on premia from the factor model or from the sample averages?\n",
    "\n",
    "Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24751b75-87fc-4fa9-98f8-f1146c35c1c2",
   "metadata": {},
   "source": [
    "- Factor model-based allocation performed better in the testing period => High Sharpe ratio and Low volatility.\n",
    "- Factor model captures systematic risk more effectively, aligning with the market rather than reflecting historical averages.\n",
    "- Using expected premia, the model provides a risk-adjusted approach for future return expectations => more stable performance under changing conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a442fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.6.\n",
    "Suppose you now want to build a tangency portfolio solely from the factors, without using the sector ETFs.\n",
    "\n",
    "- Calculate the weights of the tangency portfolio using `training` data for the factors.\n",
    "- Again, regularize the covariance matrix of factor returns by dividing off-diagonal elements by 2.\n",
    "\n",
    "Report, in the `testing` period, the factor-based tangency stats **annualized**...\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51026c43-00c4-4716-8703-a03d8d9e502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.062376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.058191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpe</th>\n",
       "      <td>1.071918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "mean    0.062376\n",
       "vol     0.058191\n",
       "sharpe  1.071918"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix_factors = df_factors_train.cov()\n",
    "diag_cov_factors = np.diag(np.diag(cov_matrix_factors))\n",
    "reg_cov_factors = (cov_matrix_factors + diag_cov_factors) / 2\n",
    "inv_reg_cov_factors = np.linalg.inv(reg_cov_factors)\n",
    "\n",
    "ones = np.ones(len(factor_premia))\n",
    "scaling_factor = 1 / (ones.T @ inv_reg_cov_factors @ factor_premia)\n",
    "factor_weights = scaling_factor * (inv_reg_cov_factors @ factor_premia)\n",
    "\n",
    "test_start, test_end = '2023-01-01', '2023-12-01'\n",
    "portfolio_returns = df_factors_test @ factor_weights\n",
    "\n",
    "calculate_univariate_statistics(portfolio_returns, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6cc36",
   "metadata": {},
   "source": [
    "### 2.7.\n",
    "\n",
    "Based on the hedge fund's beliefs, would you prefer to use the ETF-based tangency or the factor-based tangency portfolio? Explain your reasoning. Note that you should answer based on broad principles and not on the particular estimation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953d1ad-d329-4df0-9b4d-78aeb7591a9b",
   "metadata": {},
   "source": [
    "- The ETF-based tangency portfolio is preferable for its diversification\n",
    "- It captures sector-specific conditions and market factors.\n",
    "- ETFs reflect the actual market dynamics => offer stability beyond model assumptions.\n",
    "- Balances systematic exposure with market factors => Better risk-adjusted returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eda25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff849e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 3. Long-Run Returns\n",
    "\n",
    "For this question, use only the sheet `factors excess returns`.\n",
    "\n",
    "Suppose we want to measure the long run returns of various pricing factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be343b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.1.\n",
    "\n",
    "Turn the data into log returns.\n",
    "- Display the first 5 rows of the data.\n",
    "\n",
    "Using these log returns, report the **annualized**\n",
    "* mean\n",
    "* vol\n",
    "* Sharpe\n",
    "\n",
    "### 3.2.\n",
    "\n",
    "Consider 15-year cumulative log excess returns. Following the assumptions and modeling of Lecture 6, report the following 15-year stats:\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe\n",
    "\n",
    "How do they compare to the estimated stats (1-year horizon) in `3.1`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6465cd1c-4e91-4719-ae17-cd6c0486e63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>0.053636</td>\n",
       "      <td>0.017349</td>\n",
       "      <td>-0.017146</td>\n",
       "      <td>0.072786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>-0.012275</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.075849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.138113</td>\n",
       "      <td>-0.010151</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>-0.100373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.038932</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>-0.021224</td>\n",
       "      <td>-0.004309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.051263</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>-0.011263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MKT       HML       RMW       UMD\n",
       "date                                              \n",
       "1980-01-01  0.053636  0.017349 -0.017146  0.072786\n",
       "1980-02-01 -0.012275  0.006081  0.000400  0.075849\n",
       "1980-03-01 -0.138113 -0.010151  0.014494 -0.100373\n",
       "1980-04-01  0.038932  0.010544 -0.021224 -0.004309\n",
       "1980-05-01  0.051263  0.003793  0.003394 -0.011263"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1\n",
    "log_returns = np.log1p(df_factors)\n",
    "log_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c68b8e-8764-4d7b-b2c3-394928ef4368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.073549</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.043540</td>\n",
       "      <td>0.050095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.158841</td>\n",
       "      <td>0.109782</td>\n",
       "      <td>0.083573</td>\n",
       "      <td>0.160433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpe</th>\n",
       "      <td>0.463033</td>\n",
       "      <td>0.180081</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.312248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MKT       HML       RMW       UMD\n",
       "mean    0.073549  0.019770  0.043540  0.050095\n",
       "vol     0.158841  0.109782  0.083573  0.160433\n",
       "sharpe  0.463033  0.180081  0.520979  0.312248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_annualized = calculate_univariate_statistics(log_returns, 12)\n",
    "summary_annualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af1bc3c-66d0-42d7-9e4b-4bd7fb4bd66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>vol</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>1.103228</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>1.793318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.296544</td>\n",
       "      <td>0.425182</td>\n",
       "      <td>0.697452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.653096</td>\n",
       "      <td>0.323676</td>\n",
       "      <td>2.017743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.751422</td>\n",
       "      <td>0.621353</td>\n",
       "      <td>1.209332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean       vol    sharpe\n",
       "MKT  1.103228  0.615188  1.793318\n",
       "HML  0.296544  0.425182  0.697452\n",
       "RMW  0.653096  0.323676  2.017743\n",
       "UMD  0.751422  0.621353  1.209332"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2\n",
    "# Note: 15 yrs interpretation - 15*Annual. Instead of using the most recent/ starting 15 years worth of data.\n",
    "annual_mean = summary_annualized.loc['mean']\n",
    "annual_vol = summary_annualized.loc['vol']\n",
    "\n",
    "mean_15yr = 15 * annual_mean\n",
    "vol_15yr = np.sqrt(15) * annual_vol\n",
    "sharpe_15yr = mean_15yr / vol_15yr\n",
    "\n",
    "summary_cum15_corrected = pd.DataFrame({\n",
    "    'mean': mean_15yr,\n",
    "    'vol': vol_15yr,\n",
    "    'sharpe': sharpe_15yr\n",
    "})\n",
    "summary_cum15_corrected\n",
    "# Reference GPT Prompt: What does it exactly mean by \"15-year cumulative log excess returns\"? How do I calculate it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd7a33-df4f-49f7-9fd8-d28f82d78974",
   "metadata": {},
   "source": [
    "- For 15 years, MKT and RMW factors improved in stability and risk-adjusted returns.\n",
    "-  HML mean is negative for cum. 15 yrs => value is not as good as growth. UMD decreased => momentum fades over time.\n",
    "-  Certain factors, like profitability, perform consistently well. Others, like value and momentum, vary in changing market dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181ba0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.3.\n",
    "\n",
    "What is the probability that momentum factor has a negative mean excess return over the next \n",
    "* single period?\n",
    "* 15 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721b3a7f-b611-4232-8bff-53d572d1be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of negative return (single period): 0.46408867614246724\n",
      "Probability of negative return (15-year period): 0.11326774683663715\n"
     ]
    }
   ],
   "source": [
    "def prob(mu, sigma, h):\n",
    "    return norm.cdf(-np.sqrt(h) * mu / sigma)\n",
    "\n",
    "mu_monthly = annual_mean['UMD'] / 12\n",
    "sigma_monthly = annual_vol['UMD'] / np.sqrt(12)\n",
    "prob_single = norm.cdf(-mu_monthly / sigma_monthly)\n",
    "\n",
    "mu_15yr = 15 * annual_mean['UMD']\n",
    "sigma_15yr = np.sqrt(15) * annual_vol['UMD']\n",
    "prob_15yr = norm.cdf(-mu_15yr / sigma_15yr)\n",
    "\n",
    "print(f\"Probability of negative return (single period): {prob_single}\")\n",
    "print(f\"Probability of negative return (15-year period): {prob_15yr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137b86c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.4.\n",
    "\n",
    "Recall from the case that momentum has been underperforming since 2009. \n",
    "\n",
    "Using data from 2009 to present, what is the probability that momentum *outperforms* the market factor over the next\n",
    "* period?\n",
    "* 15 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5c537f-08a6-4405-acea-c8ab8f4e2d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of UMD outperforming MKT (single period): 0.4239310918100311\n",
      "Probability of UMD outperforming MKT (15-year period): 0.0050280337865116044\n"
     ]
    }
   ],
   "source": [
    "log_returns_2009 = log_returns.loc['2009-01-01':]\n",
    "\n",
    "annual_mean_2009 = log_returns_2009.mean() * 12\n",
    "annual_vol_2009 = log_returns_2009.std() * np.sqrt(12)\n",
    "\n",
    "mu_diff_monthly = (annual_mean_2009['UMD'] - annual_mean_2009['MKT']) / 12\n",
    "sigma_diff_monthly = np.sqrt((annual_vol_2009['UMD']**2 + annual_vol_2009['MKT']**2) / 12)\n",
    "prob_single = norm.cdf(mu_diff_monthly / sigma_diff_monthly)\n",
    "\n",
    "mu_diff_15yr = 15 * (annual_mean_2009['UMD'] - annual_mean_2009['MKT'])\n",
    "sigma_diff_15yr = np.sqrt(15) * np.sqrt(annual_vol_2009['UMD']**2 + annual_vol_2009['MKT']**2)\n",
    "prob_15yr = norm.cdf(mu_diff_15yr / sigma_diff_15yr)\n",
    "\n",
    "print(f\"Probability of UMD outperforming MKT (single period): {prob_single}\")\n",
    "print(f\"Probability of UMD outperforming MKT (15-year period): {prob_15yr}\")\n",
    "# Reference: HW 6 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678bc07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.5.\n",
    "Conceptually, why is there such a discrepancy between this probability for 1 period vs. 15 years?\n",
    "\n",
    "What assumption about the log-returns are we making when we use this technique to estimate underperformance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc950819-d221-499f-9a6b-876a6e0221f0",
   "metadata": {},
   "source": [
    "- Over a single period, market randomness can overshadow expected returns, making negative outcomes fairly likely.\n",
    "- Over 15 years, the expected returns accumulate linearly, while volatility increases only with the square root of time.\n",
    "- This sub-additivity => the cumulative expected gain outperforms the growth in uncertainty, reducing the probability of underperformance over longer horizons.\n",
    "\n",
    "\n",
    "- We are assuming that log returns are independent and normally distributed.\n",
    "- This allows us to scale the mean linearly with time and the standard deviation with the square root of time, using the properties of the normal distribution to estimate probabilities across different time frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f33b7",
   "metadata": {},
   "source": [
    "### 3.6.\n",
    "\n",
    "Using your previous answers, explain what is meant by time diversification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c8034-1b29-4ce1-9956-977a40cb385d",
   "metadata": {},
   "source": [
    "- Time diversification => investing over longer periods reduces the relative impact of volatility on cumulative returns.\n",
    "- Short-term returns are unpredictable; over time, the expected gains compound, and the effect of volatility diminishes proportionally.\n",
    "- Time acts as a stabilizer, increasing the likelihood that the average return will prevail over random fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5080207",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.7.\n",
    "\n",
    "Is the probability that `HML` and `UMD` both have negative cumulative returns over the next year higher or lower than the probability that `HML` and `MKT` both have negative cumulative returns over the next year?\n",
    "\n",
    "Answer conceptually, but specifically. (No need to calculate the specific probabilities.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839afd42-4386-4f73-a41a-18a07ea550e7",
   "metadata": {},
   "source": [
    "- The probability that HML and MKT both have negative cumulative returns over the next year is higher than that for HML and UMD.\n",
    "- HML and MKT are more positively correlatedâ€”they often respond similarly to market conditions.\n",
    "- When the market declines, both underperform.\n",
    "- HML and UMD are less correlated.\n",
    "- The chance of both experiencing negative returns simultaneously is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf51ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
